name: "VGG_ILSVRC_16"

input: "data"
input_dim: 1
input_dim: 3
input_dim: 224
input_dim: 224

input: "labels"
input_dim: 1 		# to be changed on-the-fly to match input dim
input_dim: 1        # 1 (face/nonface)
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)

input: "labels_weights"
input_dim: 1 		# to be changed on-the-fly to match input dim
input_dim: 1        # 1 (face/nonface)      
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)

input: "bbox_targets"
input_dim: 1  		# to be changed on-the-fly to match input dim
input_dim: 4  		# 4 (coords)
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)

input: "bbox_loss_weights"
input_dim: 1  		# to be changed on-the-fly to match input dim
input_dim: 1  		# 4 (coords) --> 1 (flag indicating whether bbox iou loss is calculated at this point)
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)


layer {
	bottom: "data"
	top: "conv1_1"
	name: "conv1_1"
	type: "Convolution"
	param {
		lr_mult: 0.0
	}
	param {
		lr_mult: 0.0
	}
	convolution_param {
		num_output: 64
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv1_1"
	top: "conv1_1"
	name: "relu1_1"
	type: "ReLU"
}

layer {
	bottom: "conv1_1"
	top: "conv1_2"
	name: "conv1_2"
	param {
		lr_mult: 0.0
	}
	param {
		lr_mult: 0.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 64
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv1_2"
	top: "conv1_2"
	name: "relu1_2"
	type: "ReLU"
}

layer {
	bottom: "conv1_2"
	top: "pool1"
	name: "pool1"
	type: "Pooling"
	pooling_param {
		pool: MAX
		kernel_size: 2
		stride: 2
	}
}

layer {
	bottom: "pool1"
	top: "conv2_1"
	name: "conv2_1"
	param {
		lr_mult: 0.0
	}
	param {
		lr_mult: 0.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 128
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv2_1"
	top: "conv2_1"
	name: "relu2_1"
	type: "ReLU"
}

layer {
	bottom: "conv2_1"
	top: "conv2_2"
	name: "conv2_2"
	param {
		lr_mult: 0.0
	}
	param {
		lr_mult: 0.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 128
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv2_2"
	top: "conv2_2"
	name: "relu2_2"
	type: "ReLU"
}

layer {
	bottom: "conv2_2"
	top: "pool2"
	name: "pool2"
	type: "Pooling"
	pooling_param {
		pool: MAX
		kernel_size: 2
		stride: 2
	}
}

layer {
	bottom: "pool2"
	top: "conv3_1"
	name: "conv3_1"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv3_1"
	top: "conv3_1"
	name: "relu3_1"
	type: "ReLU"
}

layer {
	bottom: "conv3_1"
	top: "conv3_2"
	name: "conv3_2"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv3_2"
	top: "conv3_2"
	name: "relu3_2"
	type: "ReLU"
}

layer {
	bottom: "conv3_2"
	top: "conv3_3"
	name: "conv3_3"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv3_3"
	top: "conv3_3"
	name: "relu3_3"
	type: "ReLU"
}

layer {
	bottom: "conv3_3"
	top: "pool3"
	name: "pool3"
	type: "Pooling"
	pooling_param {
		pool: MAX
		kernel_size: 2
		stride: 2
	}
}

layer {
	bottom: "pool3"
	top: "conv4_1"
	name: "conv4_1"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 512
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv4_1"
	top: "conv4_1"
	name: "relu4_1"
	type: "ReLU"
}

layer {
	bottom: "conv4_1"
	top: "conv4_2"
	name: "conv4_2"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 512
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv4_2"
	top: "conv4_2"
	name: "relu4_2"
	type: "ReLU"
}

layer {
	bottom: "conv4_2"
	top: "conv4_3"
	name: "conv4_3"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 512
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv4_3"
	top: "conv4_3"
	name: "relu4_3"
	type: "ReLU"
}



#-----------------------layer +-------------------------
layer {
   name: "conv_proposal1"
   type: "Convolution"
   bottom: "conv4_3"
   top: "conv_proposal1"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
   convolution_param{
	   num_output: 512
	   kernel_size: 3
	   pad: 1
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 0
	   }
   }
}

layer {
   name: "relu_proposal1"
   type: "ReLU"
   bottom: "conv_proposal1"
   top: "conv_proposal1"
}

#layer {
#  name: "conv_proposal1_norm"
#  type: "LRN"
#  bottom: "conv_proposal1"
#  top: "conv_proposal1_norm"
#  lrn_param {
#    local_size: 5
#    alpha: 0.0001
#    beta: 0.75
#  }
#}

layer {
   name: "proposal_cls_score"
   type: "Convolution"
   bottom: "conv_proposal1" #"conv_proposal1_norm"
   top: "proposal_cls_score"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
   convolution_param{
	   num_output: 2   # 2(bg/fg) * 9(anchors) 
	   kernel_size: 1
	   pad: 0
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 0
	   }
   }
}

# ====================begin inception layer (add some layers before doing bbox reg)=======================

# first do a BN and a scaling
#layer {
#   bottom: "conv_proposal1"
#   top: "conv_proposal1_norm"
#   name: "bn_conv_proposal1"
#   type: "BatchNorm"
#   batch_norm_param 
#   {
#	use_global_stats: true
#   }
#}

# ------part 1-------------------------------------------------------------------
layer {
  name: "inception_3a/1x1"
  type: "Convolution"
  bottom: "conv_proposal1" #"conv_proposal1_norm"
  top: "inception_3a/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128 #64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}

layer {
  name: "inception_3a/relu_1x1"
  type: "ReLU"
  bottom: "inception_3a/1x1"
  top: "inception_3a/1x1"
}

# ------part 2---------------------------------------------------------------
layer {
  name: "inception_3a/3x3_reduce"
  type: "Convolution"
  bottom: "conv_proposal1" #"conv_proposal1_norm"
  top: "inception_3a/3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256 #96
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}

layer {
  name: "inception_3a/relu_3x3_reduce"
  type: "ReLU"
  bottom: "inception_3a/3x3_reduce"
  top: "inception_3a/3x3_reduce"
}

layer {
  name: "inception_3a/3x3"
  type: "Convolution"
  bottom: "inception_3a/3x3_reduce"
  top: "inception_3a/3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256 #128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}

layer {
  name: "inception_3a/relu_3x3"
  type: "ReLU"
  bottom: "inception_3a/3x3"
  top: "inception_3a/3x3"
}

# ------part 3-----------------------------------------------------------------
layer {
  name: "inception_3a/5x5_reduce"
  type: "Convolution"
  bottom: "conv_proposal1" #"conv_proposal1_norm"
  top: "inception_3a/5x5_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64 #16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}

layer {
  name: "inception_3a/relu_5x5_reduce"
  type: "ReLU"
  bottom: "inception_3a/5x5_reduce"
  top: "inception_3a/5x5_reduce"
}

layer {
  name: "inception_3a/5x5"
  type: "Convolution"
  bottom: "inception_3a/5x5_reduce"
  top: "inception_3a/5x5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64 #32
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}

layer {
  name: "inception_3a/relu_5x5"
  type: "ReLU"
  bottom: "inception_3a/5x5"
  top: "inception_3a/5x5"
}

# ------part 4-----------------------------------------------------------------
layer {
  name: "inception_3a/pool"
  type: "Pooling"
  bottom: "conv_proposal1" #"conv_proposal1_norm"
  top: "inception_3a/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}

layer {
  name: "inception_3a/pool_proj"
  type: "Convolution"
  bottom: "inception_3a/pool"
  top: "inception_3a/pool_proj"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64 #32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}

layer {
  name: "inception_3a/relu_pool_proj"
  type: "ReLU"
  bottom: "inception_3a/pool_proj"
  top: "inception_3a/pool_proj"
}

layer {
  name: "inception_3a/output"
  type: "Concat"
  bottom: "inception_3a/1x1" #128
  bottom: "inception_3a/3x3" #256
  bottom: "inception_3a/5x5" #64
  bottom: "inception_3a/pool_proj" #64
  top: "inception_3a/output"
}

# ====================end inception layer=================

layer {
   name: "proposal_bbox_pred"
   type: "Convolution"
   bottom: "inception_3a/output" #"conv_proposal1"
   top: "proposal_bbox_pred"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
   convolution_param{
	   num_output: 4	# 4 * 9(anchors) 
	   kernel_size: 1
	   pad: 0
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 0
	   }
   }
}

layer {
  name: "relu_bbox_pred"
  type: "ReLU"
  bottom: "proposal_bbox_pred"
  top: "proposal_bbox_pred"
}


######## previously scaling is here
layer {
    bottom: "proposal_bbox_pred"
    top: "proposal_bbox_pred"
    name: "scale_bbox_pred"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

#-----------------------output------------------------

layer {
   name: "loss"
   type: "SoftmaxWithLoss"
   bottom: "proposal_cls_score"
   bottom: "labels"
   bottom: "labels_weights"
   top: "loss_cls"
   loss_weight: 1
}

layer {
   name: "accuarcy"
   type: "Accuracy"
   bottom: "proposal_cls_score"
   bottom: "labels"
   top: "accuarcy"
}

layer {
  name: "loss_bbox"
  type: "IouLoss" #"SmoothL1Loss"
  bottom: "proposal_bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_loss_weights"
  top: "loss_bbox"
  loss_weight: 1  #1028: 5-->1
}

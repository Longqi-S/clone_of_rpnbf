name: "VGG_ILSVRC_16"

input: "data"
input_dim: 1
input_dim: 3
input_dim: 224
input_dim: 224

input: "labels"
input_dim: 1 		# to be changed on-the-fly to match input dim
input_dim: 7        # 7(anchors)        
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)

#input: "labels_weights"
#input_dim: 1 		# to be changed on-the-fly to match input dim
#input_dim: 7        # 7(anchors)        
#input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)
#input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)

input: "bbox_targets"
input_dim: 1  		# to be changed on-the-fly to match input dim
input_dim: 28  		# 4 (coords) * 7(anchors) 
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)

input: "bbox_loss_weights"
input_dim: 1  		# to be changed on-the-fly to match input dim
input_dim: 28  		# 4 (coords) * 7(anchors) 
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)
input_dim: 28  		# size for 224 input image, to be changed on-the-fly to match input dim, 14--> 28 (resolution doubled)


layer {
	bottom: "data"
	top: "conv1_1"
	name: "conv1_1"
	type: "Convolution"
	param {
		lr_mult: 0.0
	}
	param {
		lr_mult: 0.0
	}
	convolution_param {
		num_output: 64
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv1_1"
	top: "conv1_1"
	name: "relu1_1"
	type: "ReLU"
}

layer {
	bottom: "conv1_1"
	top: "conv1_2"
	name: "conv1_2"
	param {
		lr_mult: 0.0
	}
	param {
		lr_mult: 0.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 64
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv1_2"
	top: "conv1_2"
	name: "relu1_2"
	type: "ReLU"
}

layer {
	bottom: "conv1_2"
	top: "pool1"
	name: "pool1"
	type: "Pooling"
	pooling_param {
		pool: MAX
		kernel_size: 2
		stride: 2
	}
}

layer {
	bottom: "pool1"
	top: "conv2_1"
	name: "conv2_1"
	param {
		lr_mult: 0.0
	}
	param {
		lr_mult: 0.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 128
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv2_1"
	top: "conv2_1"
	name: "relu2_1"
	type: "ReLU"
}

layer {
	bottom: "conv2_1"
	top: "conv2_2"
	name: "conv2_2"
	param {
		lr_mult: 0.0
	}
	param {
		lr_mult: 0.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 128
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv2_2"
	top: "conv2_2"
	name: "relu2_2"
	type: "ReLU"
}

layer {
	bottom: "conv2_2"
	top: "pool2"
	name: "pool2"
	type: "Pooling"
	pooling_param {
		pool: MAX
		kernel_size: 2
		stride: 2
	}
}

layer {
	bottom: "pool2"
	top: "conv3_1"
	name: "conv3_1"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv3_1"
	top: "conv3_1"
	name: "relu3_1"
	type: "ReLU"
}

layer {
	bottom: "conv3_1"
	top: "conv3_2"
	name: "conv3_2"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv3_2"
	top: "conv3_2"
	name: "relu3_2"
	type: "ReLU"
}

layer {
	bottom: "conv3_2"
	top: "conv3_3"
	name: "conv3_3"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv3_3"
	top: "conv3_3"
	name: "relu3_3"
	type: "ReLU"
}

layer {
	bottom: "conv3_3"
	top: "pool3"
	name: "pool3"
	type: "Pooling"
	pooling_param {
		pool: MAX
		kernel_size: 2
		stride: 2
	}
}

layer {
	bottom: "pool3"
	top: "conv4_1"
	name: "conv4_1"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 512
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv4_1"
	top: "conv4_1"
	name: "relu4_1"
	type: "ReLU"
}

layer {
	bottom: "conv4_1"
	top: "conv4_2"
	name: "conv4_2"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 512
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv4_2"
	top: "conv4_2"
	name: "relu4_2"
	type: "ReLU"
}

layer {
	bottom: "conv4_2"
	top: "conv4_3"
	name: "conv4_3"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 512
		pad: 1
		kernel_size: 3
	}
}

layer {
	bottom: "conv4_3"
	top: "conv4_3"
	name: "relu4_3"
	type: "ReLU"
}



#-----------------------layer +-------------------------
layer {
   name: "conv_proposal1"
   type: "Convolution"
   bottom: "conv4_3"
   top: "conv_proposal1"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
   convolution_param{
	   num_output: 512
	   kernel_size: 3
	   pad: 1
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 0
	   }
   }
}

layer {
   name: "relu_proposal1"
   type: "ReLU"
   bottom: "conv_proposal1"
   top: "conv_proposal1"
}

layer {
   name: "proposal_cls_score"
   type: "Convolution"
   bottom: "conv_proposal1"
   top: "proposal_cls_score"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
   convolution_param{
	   num_output: 14   # 2(bg/fg) * 9(anchors) 
	   kernel_size: 1
	   pad: 0
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 0
	   }
   }
}

layer {
   name: "proposal_bbox_pred"
   type: "Convolution"
   bottom: "conv_proposal1"
   top: "proposal_bbox_pred"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
   convolution_param{
	   num_output: 28	# 4 * 9(anchors) 
	   kernel_size: 1
	   pad: 0
	   stride: 1
	   weight_filler {
		 type: "gaussian"
		 std: 0.01
	   }
	   bias_filler {
		 type: "constant"
		 value: 0
	   }
   }
}

#-----------------------output------------------------

# to enable the calculation of softmax loss, we first reshape blobs related to SoftmaxWithLoss
layer {
   bottom: "proposal_cls_score"
   top: "proposal_cls_score_reshape"
   name: "proposal_cls_score_reshape"
   type: "Reshape"
   reshape_param{
	   shape {
			dim: 0    # 1  -- 1
			dim: 2    # 14 -- 2
			dim: -1   # 28 -- 7*28
			dim: 0    # 28 -- 28
		}
	}
}

layer {
   bottom: "labels"
   top: "labels_reshape"
   name: "labels_reshape"
   type: "Reshape"
   reshape_param{
	   shape {
			dim: 0    # 1 -- 1
			dim: 1    # 7 -- 1
			dim: -1   # 28 -- 7*28
			dim: 0    # 28 -- 28
		}
	}
}

#layer {
#   bottom: "labels_weights"
#   top: "labels_weights_reshape"
#   name: "labels_weights_reshape"
#   type: "Reshape"
#   reshape_param{
#	   shape {
#			dim: 0   # 1 -- 1
#			dim: 1   # 7 -- 1
#			dim: -1  # 28 -- 7*28
#			dim: 0   # 28 -- 28
#		}
#	}
#}

layer {
   name: "accuarcy"
   type: "Accuracy"
   bottom: "proposal_cls_score_reshape"
   bottom: "labels_reshape"
   top: "accuarcy"
}


# previous bbox regress func
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "proposal_bbox_pred" #[1 28 28 28]
  bottom: "bbox_targets"       #[1 28 28 28]
  bottom: "bbox_loss_weights"  #[1 28 28 28]
  top: "loss_bbox"
  loss_weight: 5  #1017: 10-->5
}

# previous loss function
layer {
   name: "loss"
   type: "SoftmaxWithLoss"
   bottom: "proposal_cls_score_reshape"
   bottom: "labels_reshape"
   #bottom: "labels_weights_reshape"
   top: "loss_cls"
   loss_weight: 1
   loss_param {
       ignore_label: -1
   }
   propagate_down: true
   propagate_down: false
}

#--------------online hard example mining--------------
#liu@1114: this layer is off-the-shelf by r-fcn caffe
layer {
   name: "per_anchor_cls_loss"
   type: "SoftmaxWithLoss"
   bottom: "proposal_cls_score_reshape"  #[1, 2, 7*28, 28]
   bottom: "labels_reshape"              #[1, 1, 7*28, 28]
   top: "temp_loss_cls"  #no use 
   top: "temp_prob_cls"  #no use
   top: "per_anchor_cls_loss"            # should be:[1, 1, 7*28, 28]
   loss_weight: 0
   loss_weight: 0
   loss_weight: 0
   propagate_down: false
   propagate_down: false
}

layer {
   # bottom: "rois"
   bottom: "per_anchor_cls_loss"  #[1, 1, 7*28, 28] == [num ch hei wid]
   bottom: "labels_reshape"	  #[1, 1, 7*28, 28]
   bottom: "bbox_loss_weights"    #[1, 4*7, 28, 28]
   top: "labels_ohem"
   top: "bbox_loss_weights_ohem"
   name: "cls_ohem"
   type: "RpnClsOHEM"
   rpn_cls_ohem_param {
        bg_per_img: 256  #256
        ignore_label: -1
   }
   propagate_down: false
   propagate_down: false
   propagate_down: false
   #propagate_down: false
}

layer {
   name: "silence"
   type: "Silence"
   bottom: "temp_loss_cls"
   bottom: "temp_prob_cls"
   # bottom: "temp_loss_bbox"
}

# final loss cls output 
layer {
   name: "loss"
   type: "SoftmaxWithLoss"
   bottom: "proposal_cls_score_reshape"
   bottom: "labels_ohem"
   top: "loss_cls"
   loss_weight: 1
   loss_param {
        ignore_label: -1
   }
   propagate_down: true
   propagate_down: false
}

layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "proposal_bbox_pred" #[1 28 28 28]
  bottom: "bbox_targets"       #[1 28 28 28]
  bottom: "bbox_loss_weights_ohem"  #[1 28 28 28]
  top: "loss_bbox"
  loss_weight: 50  #1017: 10-->5
}

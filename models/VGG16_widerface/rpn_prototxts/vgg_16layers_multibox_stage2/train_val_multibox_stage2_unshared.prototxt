name: "VGG_ILSVRC_16"

input: "data"
input_dim: 1
input_dim: 3
input_dim: 224
input_dim: 224

input: "rois"
input_dim: 1 # to be changed on-the-fly to num ROIs
input_dim: 5 # [batch ind, x1, y1, x2, y2] zero-based indexing
input_dim: 1
input_dim: 1

input: "labels"
input_dim: 1 # to be changed on-the-fly to match num ROIs
input_dim: 1
input_dim: 1
input_dim: 1

input: "bbox_targets"
input_dim: 1  # to be changed on-the-fly to match num ROIs
input_dim: 4 # 4 * (K+1) (=21) classes. 1208: 8-->4
input_dim: 1
input_dim: 1

input: "bbox_loss_weights"
input_dim: 1  # to be changed on-the-fly to match num ROIs
input_dim: 4 # 4 * (K+1) (=21) classes. 1208: 8-->4
input_dim: 1
input_dim: 1

layer {
	bottom: "data"
	top: "conv1_1"
	name: "conv1_1"
	type: "Convolution"
	param {
		lr_mult: 0.0
	}
	param {
		lr_mult: 0.0
	}
	convolution_param {
		num_output: 64
		pad: 1
		kernel_size: 3
		engine: CUDNN
	}
}

layer {
	bottom: "conv1_1"
	top: "conv1_1"
	name: "relu1_1"
	type: "ReLU"
}

layer {
	bottom: "conv1_1"
	top: "conv1_2"
	name: "conv1_2"
	param {
		lr_mult: 0.0
	}
	param {
		lr_mult: 0.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 64
		pad: 1
		kernel_size: 3
		engine: CUDNN
	}
}

layer {
	bottom: "conv1_2"
	top: "conv1_2"
	name: "relu1_2"
	type: "ReLU"
}

layer {
	bottom: "conv1_2"
	top: "pool1"
	name: "pool1"
	type: "Pooling"
	pooling_param {
		pool: MAX
		kernel_size: 2
		stride: 2
	}
}

layer {
	bottom: "pool1"
	top: "conv2_1"
	name: "conv2_1"
	param {
		lr_mult: 0.0
	}
	param {
		lr_mult: 0.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 128
		pad: 1
		kernel_size: 3
		engine: CUDNN
	}
}

layer {
	bottom: "conv2_1"
	top: "conv2_1"
	name: "relu2_1"
	type: "ReLU"
}

layer {
	bottom: "conv2_1"
	top: "conv2_2"
	name: "conv2_2"
	param {
		lr_mult: 0.0
	}
	param {
		lr_mult: 0.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 128
		pad: 1
		kernel_size: 3
		engine: CUDNN
	}
}

layer {
	bottom: "conv2_2"
	top: "conv2_2"
	name: "relu2_2"
	type: "ReLU"
}

layer {
	bottom: "conv2_2"
	top: "pool2"
	name: "pool2"
	type: "Pooling"
	pooling_param {
		pool: MAX
		kernel_size: 2
		stride: 2
	}
}

layer {
	bottom: "pool2"
	top: "conv3_1"
	name: "conv3_1"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		pad: 1
		kernel_size: 3
		engine: CUDNN
	}
}

layer {
	bottom: "conv3_1"
	top: "conv3_1"
	name: "relu3_1"
	type: "ReLU"
}

layer {
	bottom: "conv3_1"
	top: "conv3_2"
	name: "conv3_2"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		pad: 1
		kernel_size: 3
		engine: CUDNN
	}
}

layer {
	bottom: "conv3_2"
	top: "conv3_2"
	name: "relu3_2"
	type: "ReLU"
}

layer {
	bottom: "conv3_2"
	top: "conv3_3"
	name: "conv3_3"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 256
		pad: 1
		kernel_size: 3
		engine: CUDNN
	}
}

layer {
	bottom: "conv3_3"
	top: "conv3_3"
	name: "relu3_3"
	type: "ReLU"
}

layer {
	bottom: "conv3_3"
	top: "pool3"
	name: "pool3"
	type: "Pooling"
	pooling_param {
		pool: MAX
		kernel_size: 2
		stride: 1
	}
}

layer {
	bottom: "pool3"
	top: "conv4_1"
	name: "conv4_1"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 512
		pad: 2
		kernel_size: 3
		dilation: 2  #filter_stride: 2
		#engine: CUDNN
	}
}

layer {
	bottom: "conv4_1"
	top: "conv4_1"
	name: "relu4_1"
	type: "ReLU"
}

layer {
	bottom: "conv4_1"
	top: "conv4_2"
	name: "conv4_2"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 512
		pad: 2
		kernel_size: 3
		dilation: 2  #filter_stride: 2
		#engine: CUDNN
	}
}

layer {
	bottom: "conv4_2"
	top: "conv4_2"
	name: "relu4_2"
	type: "ReLU"
}

layer {
	bottom: "conv4_2"
	top: "conv4_3"
	name: "conv4_3"
	param {
		lr_mult: 1.0
	}
	param {
		lr_mult: 2.0
	}
	type: "Convolution"
	convolution_param {
		num_output: 512
		pad: 2
		kernel_size: 3
		dilation: 2  #filter_stride: 2
		#engine: CUDNN
	}
}

layer {
	bottom: "conv4_3"
	top: "conv4_3"
	name: "relu4_3"
	type: "ReLU"
}


# ------------- roi layer --------
#1207 added normalization
layer {
  name: "conv3_3_norm"
  type: "Normalize"
  bottom: "conv3_3"
  top: "conv3_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 66.84  #1120: 20-->40, since its channel is only 256, so need 80?
    }
    channel_shared: false
  }
}

layer {
	bottom: "conv3_3_norm"
	bottom: "rois"
	top: "roi_pool3"
	name: "roi_pool3"
	type: "ROIPooling"
	roi_pooling_param {
		pooled_w: 4 #3  1021: 4-->5
		pooled_h: 4 #3 1021: 4-->5
		spatial_scale: 0.25  # (1/4)
	}
}

#1207 added normlization
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 94.52
    }
    channel_shared: false
  }
}

layer {
	bottom: "conv4_3_norm"
	bottom: "rois"
	top: "roi_pool4_3"
	name: "roi_pool4_3"
	type: "ROIPooling"
	roi_pooling_param {
		pooled_w: 4 #3 1021: 4-->5
		pooled_h: 4 #3 1021: 4-->5
		spatial_scale: 0.25  # (1/4)
	}
}

layer {
    bottom: "roi_pool3"  #"roi_pool3_flat"
	bottom: "roi_pool4_3" #"roi_pool4_3_flat"
	top: "concat_roi_feat"
	name: "concat_roi_feat"
	type: "Concat"
	concat_param {
		axis: 1  #concat along channels
	}
}

layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "concat_roi_feat"  #"pool5"
  top: "fc6"
  param {
    name: "fc6_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    name: "fc7_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}

layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    name: "cls_score_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "cls_score_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2 #21
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    name: "bbox_pred_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "bbox_pred_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4 #84-->8-->4
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

#-------------- begin online hard example mining--------------
layer {
   name: "per_roi_loss_cls"
   type: "SoftmaxWithLoss"
   bottom: "cls_score"
   bottom: "labels"
   top: "temp_loss_cls"
   top: "temp_prob_cls"
   top: "per_roi_loss_cls"
   loss_weight: 0
   loss_weight: 0
   loss_weight: 0
   propagate_down: false
   propagate_down: false
}

layer {
   name: "per_roi_loss_bbox"
   type: "SmoothL1Loss"
   bottom: "bbox_pred"
   bottom: "bbox_targets"
   bottom: "bbox_loss_weights"
   top: "temp_loss_bbox"
   top: "per_roi_loss_bbox"
   loss_weight: 0
   loss_weight: 0
   propagate_down: false
   propagate_down: false
   propagate_down: false
}

layer {
   name: "per_roi_loss"
   type: "Eltwise"
   bottom: "per_roi_loss_cls"
   bottom: "per_roi_loss_bbox"
   top: "per_roi_loss"
   propagate_down: false
   propagate_down: false
}

layer {
   bottom: "rois"
   bottom: "per_roi_loss"
   bottom: "labels"
   bottom: "bbox_loss_weights"
   top: "labels_ohem"
   top: "bbox_loss_weights_ohem"
   name: "annotator_detector"
   type: "BoxAnnotatorOHEM"
   box_annotator_ohem_param {
        roi_per_img: 128
        ignore_label: -1
   }
   propagate_down: false
   propagate_down: false
   propagate_down: false
   propagate_down: false
}

layer {
   name: "silence"
   type: "Silence"
   bottom: "temp_loss_cls"
   bottom: "temp_prob_cls"
   bottom: "temp_loss_bbox"
}

#-------------- end online hard example mining--------------

# ============= backpropagated loss function ===============
layer {
   name: "loss_cls"
   type: "SoftmaxWithLoss"
   bottom: "cls_score"
   bottom: "labels_ohem"
   top: "loss_cls"
   propagate_down: true
   propagate_down: false
   #1208 added because ohem creates ignore labels
   loss_param {
        ignore_label: -1
   }
   loss_weight: 1
}

layer {
   name: "loss_bbox"
   type: "SmoothL1Loss"
   bottom: "bbox_pred"
   bottom: "bbox_targets"
   bottom: "bbox_loss_weights_ohem"
   top: "loss_bbox"
   loss_weight: 1  #1207: 5-->1
   loss_param {
        normalization: PRE_FIXED
        pre_fixed_normalizer: 32 #1207: 256 --> 32 (=0.25 fg_ratio x 128 batch_size_per_img)
   }
   propagate_down: true
   propagate_down: false
   propagate_down: false
}

layer {
   name: "accuarcy"
   type: "Accuracy"
   bottom: "cls_score"
   bottom: "labels_ohem"
   top: "accuarcy"
   #include: { phase: TEST }
   accuracy_param {
        ignore_label: -1
   }
   propagate_down: false
   propagate_down: false
}
